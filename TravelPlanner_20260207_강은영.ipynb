{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4995a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7875\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7875/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ“ í˜„ì¬ ì…ë ¥ ë©”ì‹œì§€: ì„œìš¸ ë˜ëŠ” ì„œìš¸ ê·¼êµ, 2026ë…„ ì„¤ë‚  ~ ì„¤ ì—°íœ´ ë§ˆì§€ë§‰ ë‚ , 1ë°• 2ì¼, ì—¬ì„± í˜¼ì, íë§ + ê´€ê´‘, 1ì¼ ì´ ì˜ˆì‚° ìµœëŒ€ 15ë§Œì› ì •ë„\n",
      "ğŸ“š History ê°œìˆ˜: 1ê°œ\n",
      "\n",
      "ğŸ”„ LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ë©”ì‹œì§€:\n",
      "  1. ğŸ¤– AI: ì•ˆë…•í•˜ì„¸ìš”! ğŸŒ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ë“œë¦¬ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì™„ë²½í•œ ì—¬í–‰ ê³„íš...\n",
      "==================================================\n",
      "\n",
      "\n",
      "==================================================\n",
      "ğŸ“ í˜„ì¬ ì…ë ¥ ë©”ì‹œì§€: ì„œìš¸ ë˜ëŠ” ì„œìš¸ ê·¼êµ, 2026ë…„ ì„¤ë‚  ~ ì„¤ ì—°íœ´ ë§ˆì§€ë§‰ ë‚ , 1ë°• 2ì¼, ì—¬ì„± í˜¼ì, íë§ + ê´€ê´‘, 1ì¼ ì´ ì˜ˆì‚° ìµœëŒ€ 15ë§Œì› ì •ë„\n",
      "ğŸ“š History ê°œìˆ˜: 1ê°œ\n",
      "\n",
      "ğŸ”„ LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ë©”ì‹œì§€:\n",
      "  1. ğŸ¤– AI: ì•ˆë…•í•˜ì„¸ìš”! ğŸŒ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ë“œë¦¬ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì™„ë²½í•œ ì—¬í–‰ ê³„íš...\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ìˆëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ì£¼ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì„ í˜¸ë„, ì˜ˆì‚°, ì¼ì •ì— ë§ì¶° êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì—¬í–‰ ê³„íšì„ ì œê³µí•©ë‹ˆë‹¤.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  AI ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (chat_history ì‚¬ìš©)\n",
    "def answer_invoke(message, history, temperature):\n",
    "    # Temperatureì— ë”°ë¼ ë§¤ë²ˆ ìƒˆë¡œìš´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=temperature,  # ì‚¬ìš©ìê°€ ì„ íƒí•œ ê°’ ì‚¬ìš©\n",
    "        top_p=0.9,\n",
    "        presence_penalty=0.3,\n",
    "        frequency_penalty=0.3,\n",
    "    )\n",
    "\n",
    "    # ì²´ì¸ ìƒì„±\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # Gradio historyë¥¼ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"ğŸ“ í˜„ì¬ ì…ë ¥ ë©”ì‹œì§€: {message}\")\n",
    "    print(f\"ğŸ“š History ê°œìˆ˜: {len(history)}ê°œ\")\n",
    "\n",
    "    history_messages = []\n",
    "    for msg in history:\n",
    "        if msg[0] is not None:  # ì‚¬ìš©ì ë©”ì‹œì§€\n",
    "            history_messages.append(HumanMessage(content=msg[0]))\n",
    "        if msg[1] is not None:  # AI ì‘ë‹µ\n",
    "            history_messages.append(AIMessage(content=msg[1]))\n",
    "\n",
    "    # ë³€í™˜ëœ íˆìŠ¤í† ë¦¬ ì¶œë ¥\n",
    "    print(f\"\\nğŸ”„ LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ë©”ì‹œì§€:\")\n",
    "    for i, msg in enumerate(history_messages, 1):\n",
    "        role = \"ğŸ‘¤ ì‚¬ìš©ì\" if isinstance(msg, HumanMessage) else \"ğŸ¤– AI\"\n",
    "        content_preview = (\n",
    "            msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
    "        )\n",
    "        print(f\"  {i}. {role}: {content_preview}\")\n",
    "    print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "    # ì²´ì¸ ì‹¤í–‰\n",
    "    response = chain.invoke({\"chat_history\": history_messages, \"user_input\": message})\n",
    "    return response\n",
    "\n",
    "\n",
    "# ì´ˆê¸° í™˜ì˜ ë©”ì‹œì§€ ì •ì˜\n",
    "initial_message = \"\"\"ì•ˆë…•í•˜ì„¸ìš”! ğŸŒ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ë“œë¦¬ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì™„ë²½í•œ ì—¬í–‰ ê³„íšì„ ìœ„í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”:\n",
    "\n",
    "ğŸ“ **ì—¬í–‰ì§€**: ì–´ë””ë¡œ ê°€ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?\n",
    "ğŸ“… **ì—¬í–‰ ê¸°ê°„**: ë©°ì¹  ë™ì•ˆ ì—¬í–‰í•˜ì‹¤ ê³„íšì¸ê°€ìš”?\n",
    "ğŸ’° **ì˜ˆì‚°**: ëŒ€ëµì ì¸ ì˜ˆì‚° ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?\n",
    "ğŸ‘¥ **ì—¬í–‰ ì¸ì›**: í˜¼ì, ê°€ì¡±, ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜ ê°€ì‹œë‚˜ìš”?\n",
    "ğŸ¯ **ì—¬í–‰ ìŠ¤íƒ€ì¼**: íœ´ì–‘, ê´€ê´‘, ì•¡í‹°ë¹„í‹°, ë§›ì§‘ íˆ¬ì–´ ë“± ì„ í˜¸í•˜ì‹œëŠ” ìŠ¤íƒ€ì¼ì´ ìˆë‚˜ìš”?\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì‹œë©´, ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ìƒì„¸íˆ ê³„íší•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤! âœˆï¸\"\"\"\n",
    "\n",
    "# Gradio Blocksë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¤ìŠ¤í…€ ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
    "with gr.Blocks(analytics_enabled=False) as demo:\n",
    "    gr.Markdown(\"# ğŸŒ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì • ê³„íš ì–´ì‹œìŠ¤í„´íŠ¸\")\n",
    "    gr.Markdown(\n",
    "        \"ì—¬í–‰ì§€, ê¸°ê°„, ì˜ˆì‚°, ì„ í˜¸ë„ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ë“œë¦½ë‹ˆë‹¤!\"\n",
    "    )\n",
    "\n",
    "    # Temperature ìŠ¬ë¼ì´ë” ì¶”ê°€\n",
    "    temperature_slider = gr.Slider(\n",
    "        minimum=0.0,\n",
    "        maximum=1.0,\n",
    "        value=0.7,\n",
    "        step=0.1,\n",
    "        label=\"ğŸ¨ ì°½ì˜ì„± ì¡°ì ˆ (Temperature)\",\n",
    "        info=\"ë‚®ì„ìˆ˜ë¡(0.0) ì¼ê´€ë˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‹µë³€, ë†’ì„ìˆ˜ë¡(1.0) ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\",\n",
    "        render=False,  # ChatInterface ë‚´ë¶€ì— í‘œì‹œ\n",
    "    )\n",
    "\n",
    "    # ì´ˆê¸° ë©”ì‹œì§€ê°€ ìˆëŠ” Chatbot ìƒì„± (íŠœí”Œ í˜•ì‹ - ì—ëŸ¬ ì•ˆ ë‚¨)\n",
    "    chatbot = gr.Chatbot(\n",
    "        value=[(None, initial_message)], \n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    # ChatInterface ìƒì„±\n",
    "    gr.ChatInterface(\n",
    "        fn=answer_invoke,\n",
    "        chatbot=chatbot,  # ì´ˆê¸° ë©”ì‹œì§€ê°€ ì„¤ì •ëœ chatbot ì‚¬ìš©\n",
    "        additional_inputs=[temperature_slider],\n",
    "        examples=[\n",
    "            [\"ì„œìš¸ì—ì„œ 2ë°• 3ì¼ ì—¬í–‰ ê³„íš ì§œì¤˜\", 0.7],      # ì¤‘ê°„ ì°½ì˜ì„± (ê· í˜•)\n",
    "            [\"ì œì£¼ë„ ê°€ì¡± ì—¬í–‰ ì¼ì • ì¶”ì²œí•´ì¤˜\", 0.3],        # ë‚®ì€ ì°½ì˜ì„± (ì•ˆì •ì )\n",
    "            [\"ìœ ëŸ½ ë°°ë‚­ì—¬í–‰ 1ì£¼ì¼ ê³„íš ë„ì™€ì¤˜\", 1.0],        # ë†’ì€ ì°½ì˜ì„± (ë‹¤ì–‘í•œ ì•„ì´ë””ì–´)\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de96167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì¢…ë£Œ\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
