{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb4995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ìˆëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ì£¼ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì„ í˜¸ë„, ì˜ˆì‚°, ì¼ì •ì— ë§ì¶° êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì—¬í–‰ ê³„íšì„ ì œê³µí•©ë‹ˆë‹¤.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  AI ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (chat_history ì‚¬ìš©)\n",
    "def answer_invoke(message, history, temperature):\n",
    "    # Temperatureì— ë”°ë¼ ë§¤ë²ˆ ìƒˆë¡œìš´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=temperature,  # ì‚¬ìš©ìê°€ ì„ íƒí•œ ê°’ ì‚¬ìš©\n",
    "        top_p=0.9,\n",
    "        presence_penalty=0.3,\n",
    "        frequency_penalty=0.3,\n",
    "    )\n",
    "\n",
    "    # ì²´ì¸ ìƒì„±\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # Gradio historyë¥¼ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"ğŸ“ í˜„ì¬ ì…ë ¥ ë©”ì‹œì§€: {message}\")\n",
    "    print(f\"ğŸ“š History ê°œìˆ˜: {len(history)}ê°œ\")\n",
    "\n",
    "    history_messages = []\n",
    "    for msg in history:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\n",
    "            content = msg[\"content\"]\n",
    "            if isinstance(content, list):\n",
    "                text_content = \" \".join(\n",
    "                    [\n",
    "                        item.get(\"text\", \"\")\n",
    "                        for item in content\n",
    "                        if item.get(\"type\") == \"text\"\n",
    "                    ]\n",
    "                )\n",
    "                history_messages.append(HumanMessage(content=text_content))\n",
    "            else:\n",
    "                history_messages.append(HumanMessage(content=content))\n",
    "        elif msg[\"role\"] == \"assistant\":\n",
    "            content = msg[\"content\"]\n",
    "            if isinstance(content, list):\n",
    "                text_content = \" \".join(\n",
    "                    [\n",
    "                        item.get(\"text\", \"\")\n",
    "                        for item in content\n",
    "                        if item.get(\"type\") == \"text\"\n",
    "                    ]\n",
    "                )\n",
    "                history_messages.append(AIMessage(content=text_content))\n",
    "            else:\n",
    "                history_messages.append(AIMessage(content=content))\n",
    "\n",
    "    # ë³€í™˜ëœ íˆìŠ¤í† ë¦¬ ì¶œë ¥\n",
    "    print(f\"\\nğŸ”„ LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ë©”ì‹œì§€:\")\n",
    "    for i, msg in enumerate(history_messages, 1):\n",
    "        role = \"ğŸ‘¤ ì‚¬ìš©ì\" if isinstance(msg, HumanMessage) else \"ğŸ¤– AI\"\n",
    "        content_preview = (\n",
    "            msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
    "        )\n",
    "        print(f\"  {i}. {role}: {content_preview}\")\n",
    "    print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "    # ì²´ì¸ ì‹¤í–‰\n",
    "    response = chain.invoke({\"chat_history\": history_messages, \"user_input\": message})\n",
    "    return response\n",
    "\n",
    "\n",
    "# ì´ˆê¸° í™˜ì˜ ë©”ì‹œì§€ ì •ì˜\n",
    "initial_message = \"\"\"ì•ˆë…•í•˜ì„¸ìš”! ğŸŒ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ë“œë¦¬ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì™„ë²½í•œ ì—¬í–‰ ê³„íšì„ ìœ„í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”:\n",
    "\n",
    "ğŸ“ **ì—¬í–‰ì§€**: ì–´ë””ë¡œ ê°€ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?\n",
    "ğŸ“… **ì—¬í–‰ ê¸°ê°„**: ë©°ì¹  ë™ì•ˆ ì—¬í–‰í•˜ì‹¤ ê³„íšì¸ê°€ìš”?\n",
    "ğŸ’° **ì˜ˆì‚°**: ëŒ€ëµì ì¸ ì˜ˆì‚° ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?\n",
    "ğŸ‘¥ **ì—¬í–‰ ì¸ì›**: í˜¼ì, ê°€ì¡±, ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜ ê°€ì‹œë‚˜ìš”?\n",
    "ğŸ¯ **ì—¬í–‰ ìŠ¤íƒ€ì¼**: íœ´ì–‘, ê´€ê´‘, ì•¡í‹°ë¹„í‹°, ë§›ì§‘ íˆ¬ì–´ ë“± ì„ í˜¸í•˜ì‹œëŠ” ìŠ¤íƒ€ì¼ì´ ìˆë‚˜ìš”?\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì‹œë©´, ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ìƒì„¸íˆ ê³„íší•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤! âœˆï¸\"\"\"\n",
    "\n",
    "# Gradio Blocksë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¤ìŠ¤í…€ ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
    "with gr.Blocks(analytics_enabled=False) as demo:\n",
    "    gr.Markdown(\"# ğŸŒ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì • ê³„íš ì–´ì‹œìŠ¤í„´íŠ¸\")\n",
    "    gr.Markdown(\n",
    "        \"ì—¬í–‰ì§€, ê¸°ê°„, ì˜ˆì‚°, ì„ í˜¸ë„ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ë“œë¦½ë‹ˆë‹¤!\"\n",
    "    )\n",
    "\n",
    "    # Temperature ìŠ¬ë¼ì´ë” ì¶”ê°€\n",
    "    temperature_slider = gr.Slider(\n",
    "        minimum=0.0,\n",
    "        maximum=1.0,\n",
    "        value=0.7,\n",
    "        step=0.1,\n",
    "        label=\"ğŸ¨ ì°½ì˜ì„± ì¡°ì ˆ (Temperature)\",\n",
    "        info=\"ë‚®ì„ìˆ˜ë¡(0.0) ì¼ê´€ë˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‹µë³€, ë†’ì„ìˆ˜ë¡(1.0) ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\",\n",
    "        render=False,  # ChatInterface ë‚´ë¶€ì— í‘œì‹œ\n",
    "    )\n",
    "\n",
    "    # ì´ˆê¸° ë©”ì‹œì§€ê°€ ìˆëŠ” Chatbot ìƒì„± (ìµœì‹  Gradio í˜•ì‹)\n",
    "    chatbot = gr.Chatbot(\n",
    "        value=[{\"role\": \"assistant\", \"content\": initial_message}], height=500\n",
    "    )\n",
    "\n",
    "    # ChatInterface ìƒì„±\n",
    "    gr.ChatInterface(\n",
    "        fn=answer_invoke,\n",
    "        chatbot=chatbot,  # ì´ˆê¸° ë©”ì‹œì§€ê°€ ì„¤ì •ëœ chatbot ì‚¬ìš©\n",
    "        additional_inputs=[temperature_slider],\n",
    "        examples=[\n",
    "            [\"ì„œìš¸ì—ì„œ 2ë°• 3ì¼ ì—¬í–‰ ê³„íš ì§œì¤˜\", 0.7],\n",
    "            [\"ì œì£¼ë„ ê°€ì¡± ì—¬í–‰ ì¼ì • ì¶”ì²œí•´ì¤˜\", 0.3],\n",
    "            [\"ìœ ëŸ½ ë°°ë‚­ì—¬í–‰ 1ì£¼ì¼ ê³„íš ë„ì™€ì¤˜\", 0.1],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de96167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì¢…ë£Œ\n",
    "demo.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
