{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2631b5",
   "metadata": {},
   "source": [
    "#  Gradio ì±—ë´‡ êµ¬í˜„ (ê°„ë‹¨í•œ QA ì• í”Œë¦¬ì¼€ì´ì…˜)\n",
    "\n",
    "### **í•™ìŠµ ëª©í‘œ**\n",
    "1. Gradio ChatInterfaceì˜ ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì´í•´í•œë‹¤\n",
    "2. LangChain LCELì„ í™œìš©í•œ ì±—ë´‡ ì²´ì¸ êµ¬ì„± ë°©ë²•ì„ í•™ìŠµí•œë‹¤\n",
    "3. ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ ê´€ë¦¬í•˜ê³  ì»¨í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ëŠ” ë°©ë²•ì„ ìµíŒë‹¤\n",
    "4. ë©€í‹°ëª¨ë‹¬ ì…ë ¥(í…ìŠ¤íŠ¸+ì´ë¯¸ì§€)ì„ ì²˜ë¦¬í•˜ëŠ” ì±—ë´‡ì„ êµ¬í˜„í•œë‹¤\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd9328",
   "metadata": {
    "id": "8bfd9328"
   },
   "source": [
    "##  í™˜ê²½ ì„¤ì •\n",
    "\n",
    "- í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "    - gradio\n",
    "    - langchain \n",
    "    - langchain-openai \n",
    "    - langchain-google-genai \n",
    "    - python-dotenv\n",
    "\n",
    "- `.env` íŒŒì¼ì— ë‹¤ìŒ API í‚¤ ì„¤ì •\n",
    "\n",
    "    ```\n",
    "    OPENAI_API_KEY=your_openai_key\n",
    "    GOOGLE_API_KEY=your_google_key\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ac3ddb",
   "metadata": {
    "id": "15ac3ddb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b8eee",
   "metadata": {
    "id": "129b8eee"
   },
   "source": [
    "## Simple QA Chain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3722db67",
   "metadata": {
    "id": "3722db67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì¼ë°˜ì ì¸ ë°©ë²•ì€ `sort()` ë©”ì„œë“œì™€ `sorted()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "1. **`list.sort()` ë©”ì„œë“œ**  \n",
      "- ë¦¬ìŠ¤íŠ¸ ìì²´ë¥¼ ì •ë ¬í•˜ë©°, ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šê³  ì›ë³¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.  \n",
      "- ì‚¬ìš©ë²•:  \n",
      "```python\n",
      "my_list = [3, 1, 4, 2]\n",
      "my_list.sort()\n",
      "print(my_list)  # ì¶œë ¥: [1, 2, 3, 4]\n",
      "```\n",
      "\n",
      "2. **`sorted()` í•¨ìˆ˜**  \n",
      "- ì›ë³¸ ë¦¬ìŠ¤íŠ¸ëŠ” ë³€ê²½í•˜ì§€ ì•Šê³  ì •ë ¬ëœ ìƒˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.  \n",
      "- ì‚¬ìš©ë²•:  \n",
      "```python\n",
      "my_list = [3, 1, 4, 2]\n",
      "sorted_list = sorted(my_list)\n",
      "print(sorted_list)  # ì¶œë ¥: [1, 2, 3, 4]\n",
      "```\n",
      "\n",
      "### ì •ë ¬ ê¸°ì¤€ ì§€ì •í•˜ê¸°\n",
      "- **`key` ì¸ì**: ì •ë ¬ ê¸°ì¤€ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
      "- **`reverse` ì¸ì**: ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ì„ ì›í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤ (`True`).\n",
      "\n",
      "ì˜ˆì œ: ë¬¸ìì—´ ê¸¸ì´ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬  \n",
      "```python\n",
      "words = ['apple', 'banana', 'cherry']\n",
      "words_sorted = sorted(words, key=len)\n",
      "print(words_sorted)  # ì¶œë ¥: ['apple', 'cherry', 'banana']\n",
      "```\n",
      "\n",
      "ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ ì˜ˆì œ:  \n",
      "```python\n",
      "numbers = [1, 3, 2, 4]\n",
      "numbers_sorted_desc = sorted(numbers, reverse=True)\n",
      "print(numbers_sorted_desc)  # ì¶œë ¥: [4, 3, 2, 1]\n",
      "```\n",
      "\n",
      "ì´ ë°©ë²•ë“¤ì„ í™œìš©í•´ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì •ë ¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ íŒŒì´ì¬(Python) ì½”ë“œ ì‘ì„±ì„ ë„ì™€ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# LLM ëª¨ë¸ ì •ì˜\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\", \n",
    "    temperature=0.3, \n",
    "    )\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ + LLM ëª¨ë¸ + ì¶œë ¥íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰\n",
    "response = chain.invoke({\n",
    "    \"user_input\": \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "})\n",
    "\n",
    "# AIì˜ ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥ \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e87eef4",
   "metadata": {
    "id": "9e87eef4"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì—ëŠ” ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ê°€ì¥ ì¼ë°˜ì ì¸ ë°©ë²•ì€ `sort()` ë©”ì„œë“œì™€ `sorted()` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
       "\n",
       "1. **`list.sort()` ë©”ì„œë“œ**  \n",
       "- ë¦¬ìŠ¤íŠ¸ ìì²´ë¥¼ ì •ë ¬í•˜ë©°, ì •ë ¬ëœ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šê³  ì›ë³¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë³€ê²½í•©ë‹ˆë‹¤.  \n",
       "- ì‚¬ìš©ë²•:  \n",
       "```python\n",
       "my_list = [3, 1, 4, 2]\n",
       "my_list.sort()\n",
       "print(my_list)  # ì¶œë ¥: [1, 2, 3, 4]\n",
       "```\n",
       "\n",
       "2. **`sorted()` í•¨ìˆ˜**  \n",
       "- ì›ë³¸ ë¦¬ìŠ¤íŠ¸ëŠ” ë³€ê²½í•˜ì§€ ì•Šê³  ì •ë ¬ëœ ìƒˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.  \n",
       "- ì‚¬ìš©ë²•:  \n",
       "```python\n",
       "my_list = [3, 1, 4, 2]\n",
       "sorted_list = sorted(my_list)\n",
       "print(sorted_list)  # ì¶œë ¥: [1, 2, 3, 4]\n",
       "```\n",
       "\n",
       "### ì •ë ¬ ê¸°ì¤€ ì§€ì •í•˜ê¸°\n",
       "- **`key` ì¸ì**: ì •ë ¬ ê¸°ì¤€ì„ ì§€ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
       "- **`reverse` ì¸ì**: ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ì„ ì›í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤ (`True`).\n",
       "\n",
       "ì˜ˆì œ: ë¬¸ìì—´ ê¸¸ì´ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬  \n",
       "```python\n",
       "words = ['apple', 'banana', 'cherry']\n",
       "words_sorted = sorted(words, key=len)\n",
       "print(words_sorted)  # ì¶œë ¥: ['apple', 'cherry', 'banana']\n",
       "```\n",
       "\n",
       "ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ ì˜ˆì œ:  \n",
       "```python\n",
       "numbers = [1, 3, 2, 4]\n",
       "numbers_sorted_desc = sorted(numbers, reverse=True)\n",
       "print(numbers_sorted_desc)  # ì¶œë ¥: [4, 3, 2, 1]\n",
       "```\n",
       "\n",
       "ì´ ë°©ë²•ë“¤ì„ í™œìš©í•´ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì •ë ¬í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ë§ˆí¬ë‹¤ìš´ ì¶œë ¥\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a59f9",
   "metadata": {},
   "source": [
    "## Gradio ChatInterface  \n",
    "- ì„¤ì¹˜: pip install gradio --upgrade , uv add gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f810a",
   "metadata": {},
   "source": [
    "### 1) ê¸°ë³¸ êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65443d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n* Running on local URL:  http://127.0.0.1:7860\\n* To create a public link, set `share=True` in `launch()`.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì…ë ¥ ë©”ì‹œì§€: hello\n",
      "----------------------------------------\n",
      "ì±„íŒ… íˆìŠ¤í† ë¦¬:\n",
      "ì…ë ¥ ë©”ì‹œì§€: who are you?\n",
      "----------------------------------------\n",
      "ì±„íŒ… íˆìŠ¤í† ë¦¬:\n",
      "ì‚¬ìš©ì: user, ë©”ì‹œì§€: [{'text': 'hello', 'type': 'text'}]\n",
      "----------------------------------------\n",
      "ì‚¬ìš©ì: assistant, ë©”ì‹œì§€: [{'text': 'ì‘ë‹µ ë©”ì‹œì§€', 'type': 'text'}]\n",
      "----------------------------------------\n",
      "ì…ë ¥ ë©”ì‹œì§€: ok\n",
      "----------------------------------------\n",
      "ì±„íŒ… íˆìŠ¤í† ë¦¬:\n",
      "ì‚¬ìš©ì: user, ë©”ì‹œì§€: [{'text': 'hello', 'type': 'text'}]\n",
      "----------------------------------------\n",
      "ì‚¬ìš©ì: assistant, ë©”ì‹œì§€: [{'text': 'ì‘ë‹µ ë©”ì‹œì§€', 'type': 'text'}]\n",
      "----------------------------------------\n",
      "ì‚¬ìš©ì: user, ë©”ì‹œì§€: [{'text': 'who are you?', 'type': 'text'}]\n",
      "----------------------------------------\n",
      "ì‚¬ìš©ì: assistant, ë©”ì‹œì§€: [{'text': 'ì‘ë‹µ ë©”ì‹œì§€', 'type': 'text'}]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# ì±—ë´‡ í•¨ìˆ˜ ì •ì˜\n",
    "def chat_function(message, history):\n",
    "    # ë©”ì‹œì§€ ì¶œë ¥\n",
    "    print(f\"ì…ë ¥ ë©”ì‹œì§€: {message}\")\n",
    "    print(\"-\"*40)\n",
    "    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì¶œë ¥\n",
    "    print(f\"ì±„íŒ… íˆìŠ¤í† ë¦¬:\")\n",
    "    for chat in history:\n",
    "        print(f\"ì‚¬ìš©ì: {chat['role']}, ë©”ì‹œì§€: {chat['content']}\")\n",
    "        print(\"-\"*40)\n",
    "    return \"ì‘ë‹µ ë©”ì‹œì§€\"\n",
    "\n",
    "# ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_function,  # ì‹¤í–‰í•  í•¨ìˆ˜\n",
    "    analytics_enabled=False,  # ì‚¬ìš© ì •ë³´ ì œê³µ ì—¬ë¶€\n",
    ")\n",
    "\n",
    "# ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "demo.launch()\n",
    "\n",
    "\"\"\"\n",
    "* Running on local URL:  http://127.0.0.1:7860\n",
    "* To create a public link, set `share=True` in `launch()`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6df357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# ì¸í„°í˜ì´ìŠ¤ ì¢…ë£Œ\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070bc3e",
   "metadata": {},
   "source": [
    "### 2) ê°„ë‹¨í•œ ì˜ˆì œ: Echo ì±—ë´‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df39e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def echo_bot(message, history):\n",
    "    return f\"ë‹¹ì‹ ì´ ì…ë ¥í•œ ë©”ì‹œì§€: {message}\"\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=echo_bot,\n",
    "    title=\"Echo ì±—ë´‡\",\n",
    "    description=\"ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ ë˜ëŒë ¤ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.\",\n",
    "    analytics_enabled=False,  \n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eea11f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c3c244",
   "metadata": {},
   "source": [
    "### 3) ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d36896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ í•¨ìˆ˜ ì •ì˜\n",
    "import time\n",
    "\n",
    "def streaming_bot(message, history):\n",
    "    response = f\"ì²˜ë¦¬ ì¤‘ì¸ ë©”ì‹œì§€: {message}\"\n",
    "    for i in range(len(response)):\n",
    "        time.sleep(0.1)          # 0.1ì´ˆ ëŒ€ê¸°\n",
    "        yield response[:i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f38cc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
    "demo = gr.ChatInterface(\n",
    "    fn=streaming_bot,\n",
    "    title=\"ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡\",\n",
    "    description=\"ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ í•œ ê¸€ìì”© ì²˜ë¦¬í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.\",\n",
    "    analytics_enabled=False,  \n",
    ")\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ffdd862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5129fcd",
   "metadata": {},
   "source": [
    "### 4) ì¶”ê°€ ì…ë ¥ ì»´í¬ë„ŒíŠ¸\n",
    "- ìµœëŒ€ ì‘ë‹µ ê¸¸ì´ ë“± ê¸°íƒ€ ì„¤ì •ì„ ìœ„í•œ ì¶”ê°€ ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d6069ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ íŒŒì´ì¬(Python) ì½”ë“œ ì‘ì„±ì„ ë„ì™€ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "\n",
    "# ì±—ë´‡ í•¨ìˆ˜ ì •ì˜\n",
    "def chat_function(message, history, model, temperature):\n",
    "\n",
    "    if model == \"gpt-4.1-nano\":\n",
    "        model = ChatOpenAI(model=model, temperature=temperature)\n",
    "    elif model == \"gemini-2.5-flash-lite\":\n",
    "        model = ChatGoogleGenerativeAI(model=model, temperature=temperature)\n",
    "\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"user_input\": message\n",
    "    })\n",
    "    return response\n",
    "\n",
    "# ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
    "with gr.Blocks() as demo:\n",
    "    model_selector = gr.Dropdown([\"gpt-4.1-nano\", \"gemini-2.5-flash-lite\"], label=\"ëª¨ë¸ ì„ íƒ\")\n",
    "    slider = gr.Slider(0.0, 1.0, label=\"Temperature\", value=0.3, step=0.1, render=False)   \n",
    "\n",
    "    gr.ChatInterface(\n",
    "        fn=chat_function, \n",
    "        additional_inputs=[model_selector, slider],\n",
    "        analytics_enabled=False,  \n",
    "    )\n",
    "\n",
    "# ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff42f636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c70ea",
   "metadata": {},
   "source": [
    "### 5) ì˜ˆì‹œ ì§ˆë¬¸ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c44c455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
    "demo = gr.ChatInterface(\n",
    "    fn=streaming_bot,\n",
    "    title=\"ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡\",\n",
    "    description=\"ì…ë ¥í•œ ë©”ì‹œì§€ë¥¼ í•œ ê¸€ìì”© ì²˜ë¦¬í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.\",\n",
    "    analytics_enabled=False,  \n",
    "    examples=[\n",
    "        \"íŒŒì´ì¬ ì½”ë“œë¥¼ ì‘ì„±í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”\",\n",
    "        \"íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì •ë ¬í•˜ëŠ” ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\",\n",
    "    ]    \n",
    ")\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¬ë° ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b16cb24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "demo.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0309e370",
   "metadata": {},
   "source": [
    "### 6) ë©€í‹°ëª¨ë‹¬ ê¸°ëŠ¥\n",
    "- `multimodal=True` ì˜µì…˜\n",
    "- ì´ë¯¸ì§€ë‚˜ íŒŒì¼ì„ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë©€í‹°ëª¨ë‹¬ ì±—ë´‡ êµ¬í˜„\n",
    "\n",
    "- message íŒŒë¼ë¯¸í„°:\n",
    "    ```python\n",
    "    {\n",
    "        \"text\": \"user input\", \n",
    "        \"files\": [\n",
    "            \"updated_file_1_path.ext\",\n",
    "            \"updated_file_2_path.ext\", \n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "    ```\n",
    "- history íŒŒë¼ë¯¸í„°:\n",
    "    ```python\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": (\"cat1.png\")},\n",
    "        {\"role\": \"user\", \"content\": (\"cat2.png\")},\n",
    "        {\"role\": \"user\", \"content\": \"What's the difference between these two images?\"},\n",
    "    ]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709da9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: []\n",
      "Filepath list: ['/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/64acc6368053ea48efe74d877ce608aee21abedc26ea8842fddb22545d2b34f5/20230816 15h photoism_key square.jpeg', '/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/8fc633a591dd278321a4ade8be3015f1d508529f23f2ea8a8a8981d949f4072d/avatar-profile.png']\n",
      "History: [{'role': 'user', 'metadata': None, 'content': [{'file': {'path': '/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/64acc6368053ea48efe74d877ce608aee21abedc26ea8842fddb22545d2b34f5/20230816 15h photoism_key square.jpeg', 'url': '/gradio_api/file=/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/64acc6368053ea48efe74d877ce608aee21abedc26ea8842fddb22545d2b34f5/20230816 15h photoism_key square.jpeg', 'size': None, 'orig_name': None, 'mime_type': 'image/jpeg', 'is_stream': False, 'meta': {'_type': 'gradio.FileData'}}, 'alt_text': None, 'type': 'file'}, {'file': {'path': '/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/8fc633a591dd278321a4ade8be3015f1d508529f23f2ea8a8a8981d949f4072d/avatar-profile.png', 'url': '/gradio_api/file=/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/8fc633a591dd278321a4ade8be3015f1d508529f23f2ea8a8a8981d949f4072d/avatar-profile.png', 'size': None, 'orig_name': None, 'mime_type': 'image/png', 'is_stream': False, 'meta': {'_type': 'gradio.FileData'}}, 'alt_text': None, 'type': 'file'}, {'text': 'ì²¨ë¶€í•œ ë‘ ì´ë¯¸ì§€ì˜ ì°¨ì´ê°€ ë­ì•¼?', 'type': 'text'}], 'options': None}, {'role': 'assistant', 'metadata': None, 'content': [{'text': 'ë‘ ì´ë¯¸ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì ì—ì„œ ì°¨ì´ê°€ ìˆìŠµë‹ˆë‹¤.\\n\\n* **ìŠ¤íƒ€ì¼:** ì²« ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” ì‹¤ì œ ì‚¬ëŒì˜ ì‚¬ì§„ì´ê³ , ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” í”½ì…€ ì•„íŠ¸ ìŠ¤íƒ€ì¼ì˜ ìºë¦­í„°ì…ë‹ˆë‹¤.\\n* **í‘œí˜„:** ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì˜ ì—¬ì„±ì€ ë¯¸ì†Œë¥¼ ì§“ê³  ìˆìœ¼ë©°, ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ì˜ ìºë¦­í„°ë„ ì›ƒëŠ” í‘œì •ì„ í•˜ê³  ìˆì§€ë§Œ í”½ì…€í™”ë˜ì–´ í‘œí˜„ì´ ë‹¨ìˆœí•©ë‹ˆë‹¤.\\n* **í˜•íƒœ:** ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì˜ ì—¬ì„±ì€ ì‹¤ì œ ì‚¬ëŒì˜ ìœ¤ê³½ì„ ê°€ì§€ê³  ìˆì§€ë§Œ, ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ì˜ ìºë¦­í„°ëŠ” ë™ê¸€ë™ê¸€í•˜ê³  ê·€ì—¬ìš´ í˜•íƒœë¡œ ë””ìì¸ë˜ì—ˆìŠµë‹ˆë‹¤.\\n* **ìƒ‰ìƒ:** ì²« ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” ì‹¤ì œ ìƒ‰ìƒì„ ë°˜ì˜í•˜ì§€ë§Œ, ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” í”½ì…€ ì•„íŠ¸ íŠ¹ì„±ìƒ ì œí•œëœ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ë¥¼ ì‚¬ìš©í•˜ë©°, ë°°ê²½ìƒ‰ë„ ë‹¤ë¦…ë‹ˆë‹¤.\\n* **ë””í…Œì¼:** ì²« ë²ˆì§¸ ì´ë¯¸ì§€ì—ëŠ” ë¨¸ë¦¬ì¹´ë½, ì˜·ì˜ ì£¼ë¦„ ë“± ë” ë§ì€ ë””í…Œì¼ì´ ìˆì§€ë§Œ, ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ëŠ” í”½ì…€í™”ë˜ì–´ ë””í…Œì¼ì´ ìµœì†Œí™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.', 'type': 'text'}], 'options': None}]\n",
      "Filepath list: ['/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/64acc6368053ea48efe74d877ce608aee21abedc26ea8842fddb22545d2b34f5/20230816 15h photoism_key square.jpeg', '/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/8fc633a591dd278321a4ade8be3015f1d508529f23f2ea8a8a8981d949f4072d/avatar-profile.png']\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "def convert_to_url(image_path):\n",
    "    \"\"\"ì´ë¯¸ì§€ë¥¼ URL í˜•ì‹ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        return f\"data:image/jpeg;base64,{encoded_string}\"\n",
    "\n",
    "def multimodal_bot(message, history):\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")\n",
    "    \n",
    "    if isinstance(message, dict):\n",
    "        # í…ìŠ¤íŠ¸ì™€ íŒŒì¼ ì¶”ì¶œ\n",
    "        text = message.get(\"text\", \"\")\n",
    "        \n",
    "        # íˆìŠ¤í† ë¦¬ì™€ í˜„ì¬ ë©”ì‹œì§€ì—ì„œ ëª¨ë“  íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ\n",
    "        filepath_list = []\n",
    "        \n",
    "        # íˆìŠ¤í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì¶”ì¶œ\n",
    "        print(\"History:\", history)  # ë””ë²„ê¹…ìš©\n",
    "        for exchange in history:\n",
    "            # user_message = exchange[0]\n",
    "            # if isinstance(user_message, tuple):  # ì´ë¯¸ì§€ ë©”ì‹œì§€ í™•ì¸\n",
    "            #     filepath_list.append(user_message[0])\n",
    "            # ìƒˆë¡œìš´ Gradio í˜•ì‹: exchangeëŠ” ë”•ì…”ë„ˆë¦¬\n",
    "            if isinstance(exchange, dict) and 'content' in exchange:\n",
    "                content = exchange['content']\n",
    "                # contentëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœ\n",
    "                if isinstance(content, list):\n",
    "                    for item in content:\n",
    "                        # íŒŒì¼ íƒ€ì… ì•„ì´í…œ ì°¾ê¸°\n",
    "                        if isinstance(item, dict) and item.get('type') == 'file':\n",
    "                            file_info = item.get('file', {})\n",
    "                            if 'path' in file_info:\n",
    "                                filepath_list.append(file_info['path'])\n",
    "        \n",
    "        # í˜„ì¬ ë©”ì‹œì§€ì˜ íŒŒì¼ë“¤ë„ ì¶”ê°€\n",
    "        files = message.get(\"files\", [])\n",
    "        filepath_list.extend(files)\n",
    "        \n",
    "        print(\"Filepath list:\", filepath_list)  # ë””ë²„ê¹…ìš©\n",
    "        \n",
    "        if filepath_list:\n",
    "            # ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬\n",
    "            image_urls = []\n",
    "            for file_path in filepath_list:\n",
    "                try:\n",
    "                    image_url = convert_to_url(file_path)\n",
    "                    image_urls.append({\"type\": \"image_url\", \"image_url\": image_url})\n",
    "                except Exception as e:\n",
    "                    print(f\"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if not image_urls:\n",
    "                return \"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
    "            \n",
    "            # ë©”ì‹œì§€ êµ¬ì„±\n",
    "            content = [\n",
    "                {\"type\": \"text\", \"text\": text if text else \"ì´ ì´ë¯¸ì§€ë“¤ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.\"},\n",
    "                *image_urls\n",
    "            ]\n",
    "            \n",
    "            try:\n",
    "                # API í˜¸ì¶œ\n",
    "                response = model.invoke([\n",
    "                    HumanMessage(content=content)\n",
    "                ])\n",
    "                return response.content\n",
    "            except Exception as e:\n",
    "                return f\"ëª¨ë¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\"\n",
    "        \n",
    "        return text if text else \"ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\"\n",
    "    \n",
    "    return \"í…ìŠ¤íŠ¸ë‚˜ ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •\n",
    "demo = gr.ChatInterface(\n",
    "    fn=multimodal_bot,\n",
    "    multimodal=True,\n",
    "    title=\"ë©€í‹°ëª¨ë‹¬ ì±—ë´‡\",\n",
    "    description=\"í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ì´ì „ ëŒ€í™”ì˜ ì´ë¯¸ì§€ë“¤ë„ í•¨ê»˜ ê³ ë ¤í•©ë‹ˆë‹¤.\",\n",
    "    analytics_enabled=False,  \n",
    "    textbox=gr.MultimodalTextbox(placeholder=\"í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\", file_count=\"multiple\", file_types=[\"image\"]),\n",
    ")\n",
    "\n",
    "# ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8086535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7863\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3e9b8",
   "metadata": {},
   "source": [
    "### 7) PDF ë·°ì–´\n",
    "- ì„¤ì¹˜: pip install gradio_pdf ë˜ëŠ” uv add gradio_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f63e62dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gradio_pdf import PDF\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    # TODO: PDF ì²˜ë¦¬ ë¡œì§ ì¶”ê°€ í•„ìš”\n",
    "    # í˜„ì¬ëŠ” ì‚¬ìš©ì ë©”ì‹œì§€ë§Œ ë°˜í™˜í•˜ëŠ” ì˜ˆì‹œì…ë‹ˆë‹¤\n",
    "    # ì‹¤ì œ êµ¬í˜„ ì‹œ PDF íŒŒì‹± ë¼ì´ë¸ŒëŸ¬ë¦¬(PyPDF2, pdfplumber ë“±) í•„ìš”\n",
    "    return message\n",
    "\n",
    "with gr.Blocks(\n",
    "    analytics_enabled=False,  \n",
    ") as demo:\n",
    "    with gr.Row():\n",
    "        # API Key Section\n",
    "        api_key_input = gr.Textbox(\n",
    "            label=\"Enter OpenAI API Key\",\n",
    "            type=\"password\",\n",
    "            placeholder=\"sk-...\"\n",
    "        )\n",
    "        \n",
    "    with gr.Row():\n",
    "        # PDF Upload and Chat Interface\n",
    "        with gr.Column(scale=2):\n",
    "            pdf_file = PDF(\n",
    "                label=\"Upload PDF File\",\n",
    "                height=600,  # PDF ë·°ì–´ ë†’ì´ ì„¤ì •\n",
    "            )\n",
    "        with gr.Column(scale=1):\n",
    "            chatbot = gr.ChatInterface(\n",
    "                fn=answer_invoke,\n",
    "                title=\"PDF-based Chatbot\",\n",
    "                description=\"Upload a PDF file and ask questions about its contents.\",\n",
    "            )\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7369f37",
   "metadata": {},
   "source": [
    "## Memory ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3d508b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat_history í”Œë ˆì´ìŠ¤í™€ë”ë¥¼ ì‚¬ìš©\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ìˆëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ë‹¹ì‹ ì€ íŒŒì´ì¬(Python) ì½”ë“œ ì‘ì„±ì„ ë„ì™€ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"system\", \"ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€í•´ì„œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ + LLM ëª¨ë¸ + ì¶œë ¥íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  AI ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (chat_history ì‚¬ìš©)\n",
    "def answer_invoke(message, history):\n",
    "\n",
    "    history_messages = []\n",
    "    for msg in history:\n",
    "        if msg['role'] == \"user\":\n",
    "            history_messages.append(HumanMessage(content=msg['content']))\n",
    "        elif msg['role'] == \"assistant\":\n",
    "            history_messages.append(AIMessage(content=msg['content']))\n",
    "\n",
    "    # history_messages.append(HumanMessage(content=message)) # ë‚˜ì˜ ì§ˆë¬¸ = ì´ lineÂ í•„ìš” ì—†ë‹¤ê³  í•˜ì‹  ì´ìœ  ì´í•´ ëª»í•¨/ì•ë’¤ ì„¤ëª… ëª» ë“¤ìŒ\n",
    "    response = chain.invoke({\n",
    "        \"chat_history\": history_messages,\n",
    "        \"user_input\": message\n",
    "    })\n",
    "    return response\n",
    "    \n",
    "\n",
    "# Gradio ChatInterface ê°ì²´ ìƒì„±\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,         # ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "    title=\"íŒŒì´ì¬ ì½”ë“œ ì–´ì‹œìŠ¤í„´íŠ¸\", # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ì˜ ì œëª©\n",
    "    )\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "576dbb2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'demo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Gradio ì¸í„°í˜ì´ìŠ¤ ì¢…ë£Œ\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdemo\u001b[49m.close()\n",
      "\u001b[31mNameError\u001b[39m: name 'demo' is not defined"
     ]
    }
   ],
   "source": [
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì¢…ë£Œ\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d46b8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# [ì‹¤ìŠµ í”„ë¡œì íŠ¸]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b260a",
   "metadata": {},
   "source": [
    "### **ë‹¤ìŒê³¼ ê°™ì€ ìš”êµ¬ì‚¬í•­ì„ Gradio ChatInterfaceë¡œ êµ¬í˜„í•©ë‹ˆë‹¤**\n",
    "\n",
    "- ì£¼ì œ: ë§ì¶¤í˜• ì—¬í–‰ ì¼ì • ê³„íš ì–´ì‹œìŠ¤í„´íŠ¸\n",
    "- ê¸°ëŠ¥: \n",
    "   - OpenAI Chat Completion APIì™€ LangChainì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì„ í˜¸ë„ì— ë§ëŠ” ì—¬í–‰ ì¼ì •ì„ ìƒì„±\n",
    "   - LCELì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ê³„ë³„ í”„ë¡¬í”„íŠ¸ ì²´ì¸ êµ¬ì„± (ì‚¬ìš©ì ì…ë ¥ ë¶„ì„ -> ì¼ì • ìƒì„± -> ì„¸ë¶€ ê³„íš ìˆ˜ë¦½)\n",
    "   - ì±„íŒ… íˆìŠ¤í† ë¦¬ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„±\n",
    "   - Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ ì‚¬ìš©ìì™€ ëŒ€í™”í˜•ìœ¼ë¡œ ìƒí˜¸ì‘ìš©\n",
    "\n",
    "- ì£¼ìš” í¬ì¸íŠ¸:\n",
    "\n",
    "   1. **ëª¨ë¸ ë§¤ê°œë³€ìˆ˜ ìµœì í™”**\n",
    "      - temperature=0.7: ì ë‹¹í•œ ì°½ì˜ì„±ì„ ìœ ì§€í•˜ë©´ì„œ ì¼ê´€ëœ ì‘ë‹µ ìƒì„±\n",
    "      - top_p=0.9: ë†’ì€ í™•ë¥ ì˜ í† í°ë§Œ ì„ íƒí•˜ì—¬ ì‘ë‹µì˜ í’ˆì§ˆ í–¥ìƒ\n",
    "      - presence_penaltyì™€ frequency_penalty: ë°˜ë³µì ì¸ ì‘ë‹µì„ ì¤„ì´ê³  ë‹¤ì–‘í•œ ì œì•ˆ ìƒì„±\n",
    "\n",
    "   2. **ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ê³„**\n",
    "      - ì—¬í–‰ í”Œë˜ë„ˆë¡œì„œì˜ ì—­í• ê³¼ ì‘ë‹µ ê°€ì´ë“œë¼ì¸ì„ ëª…í™•íˆ ì •ì˜\n",
    "      - êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ í¬í•¨í•˜ë„ë¡ ì§€ì‹œ\n",
    "      - í•œêµ­ì–´ ì‘ë‹µ ëª…ì‹œ\n",
    "\n",
    "   3. **ë©”ëª¨ë¦¬ ê´€ë¦¬**\n",
    "      - Gradio ë˜ëŠ” LangChain ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€\n",
    "      - ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì—°ì†ì„± ìˆëŠ” ì‘ë‹µ ìƒì„±\n",
    "\n",
    "### ë‹¨ê³„ë³„ êµ¬í˜„ ê°€ì´ë“œ\n",
    "\n",
    "- **Step 1**: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì‘ì„±\n",
    "   - ì—¬í–‰ í”Œë˜ë„ˆì˜ ì—­í•  ëª…ì‹œ\n",
    "   - êµ¬ì²´ì ì¸ ì •ë³´ í¬í•¨ ì§€ì‹œ (ë‚ ì§œ, ì¥ì†Œ, ì˜ˆì‚° ë“±)\n",
    "\n",
    "- **Step 2**: ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬\n",
    "   - MessagesPlaceholder ì‚¬ìš©\n",
    "   - HumanMessage/AIMessage ë³€í™˜\n",
    "\n",
    "- **Step 3**: Gradio ì¸í„°í˜ì´ìŠ¤ ì„¤ì •\n",
    "   - ì œëª©ê³¼ ì„¤ëª… ì¶”ê°€\n",
    "\n",
    "**Step 4**: í…ŒìŠ¤íŠ¸\n",
    "   - \"ì„œìš¸ì—ì„œ 2ë°• 3ì¼ ì—¬í–‰ ê³„íš ì§œì¤˜\" ë“±ì˜ ì§ˆë¬¸ ì‹œë„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5763e1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ìˆëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"ë‹¹ì‹ ì€ ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ì£¼ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì„ í˜¸ë„, ì˜ˆì‚°, ì¼ì •ì— ë§ì¶° êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì—¬í–‰ ê³„íšì„ ì œê³µí•©ë‹ˆë‹¤.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  AI ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (chat_history ì‚¬ìš©)\n",
    "def answer_invoke(message, history, temperature):\n",
    "    # Temperatureì— ë”°ë¼ ë§¤ë²ˆ ìƒˆë¡œìš´ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "    model = ChatOpenAI(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=temperature,  # ì‚¬ìš©ìê°€ ì„ íƒí•œ ê°’ ì‚¬ìš©\n",
    "        top_p=0.9,\n",
    "        presence_penalty=0.3,\n",
    "        frequency_penalty=0.3,\n",
    "    )\n",
    "\n",
    "    # ì²´ì¸ ìƒì„±\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    # Gradio historyë¥¼ LangChain ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"ğŸ“ í˜„ì¬ ì…ë ¥ ë©”ì‹œì§€: {message}\")\n",
    "    print(f\"ğŸ“š History ê°œìˆ˜: {len(history)}ê°œ\")\n",
    "\n",
    "    history_messages = []\n",
    "    for msg in history:\n",
    "        if msg[\"role\"] == \"user\":\n",
    "            # contentê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ\n",
    "            content = msg[\"content\"]\n",
    "            if isinstance(content, list):\n",
    "                text_content = \" \".join(\n",
    "                    [\n",
    "                        item.get(\"text\", \"\")\n",
    "                        for item in content\n",
    "                        if item.get(\"type\") == \"text\"\n",
    "                    ]\n",
    "                )\n",
    "                history_messages.append(HumanMessage(content=text_content))\n",
    "            else:\n",
    "                history_messages.append(HumanMessage(content=content))\n",
    "        elif msg[\"role\"] == \"assistant\":\n",
    "            content = msg[\"content\"]\n",
    "            if isinstance(content, list):\n",
    "                text_content = \" \".join(\n",
    "                    [\n",
    "                        item.get(\"text\", \"\")\n",
    "                        for item in content\n",
    "                        if item.get(\"type\") == \"text\"\n",
    "                    ]\n",
    "                )\n",
    "                history_messages.append(AIMessage(content=text_content))\n",
    "            else:\n",
    "                history_messages.append(AIMessage(content=content))\n",
    "\n",
    "    # ë³€í™˜ëœ íˆìŠ¤í† ë¦¬ ì¶œë ¥\n",
    "    print(f\"\\nğŸ”„ LangChain í˜•ì‹ìœ¼ë¡œ ë³€í™˜ëœ ë©”ì‹œì§€:\")\n",
    "    for i, msg in enumerate(history_messages, 1):\n",
    "        role = \"ğŸ‘¤ ì‚¬ìš©ì\" if isinstance(msg, HumanMessage) else \"ğŸ¤– AI\"\n",
    "        content_preview = (\n",
    "            msg.content[:50] + \"...\" if len(msg.content) > 50 else msg.content\n",
    "        )\n",
    "        print(f\"  {i}. {role}: {content_preview}\")\n",
    "    print(f\"{'=' * 50}\\n\")\n",
    "\n",
    "    # ì²´ì¸ ì‹¤í–‰\n",
    "    response = chain.invoke({\"chat_history\": history_messages, \"user_input\": message})\n",
    "    return response\n",
    "\n",
    "\n",
    "# ì´ˆê¸° í™˜ì˜ ë©”ì‹œì§€ ì •ì˜\n",
    "initial_message = \"\"\"ì•ˆë…•í•˜ì„¸ìš”! ğŸŒ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ë“œë¦¬ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì™„ë²½í•œ ì—¬í–‰ ê³„íšì„ ìœ„í•´ ë‹¤ìŒ ì •ë³´ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”:\n",
    "\n",
    "ğŸ“ **ì—¬í–‰ì§€**: ì–´ë””ë¡œ ê°€ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?\n",
    "ğŸ“… **ì—¬í–‰ ê¸°ê°„**: ë©°ì¹  ë™ì•ˆ ì—¬í–‰í•˜ì‹¤ ê³„íšì¸ê°€ìš”?\n",
    "ğŸ’° **ì˜ˆì‚°**: ëŒ€ëµì ì¸ ì˜ˆì‚° ë²”ìœ„ëŠ” ì–´ë–»ê²Œ ë˜ì‹œë‚˜ìš”?\n",
    "ğŸ‘¥ **ì—¬í–‰ ì¸ì›**: í˜¼ì, ê°€ì¡±, ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜ ê°€ì‹œë‚˜ìš”?\n",
    "ğŸ¯ **ì—¬í–‰ ìŠ¤íƒ€ì¼**: íœ´ì–‘, ê´€ê´‘, ì•¡í‹°ë¹„í‹°, ë§›ì§‘ íˆ¬ì–´ ë“± ì„ í˜¸í•˜ì‹œëŠ” ìŠ¤íƒ€ì¼ì´ ìˆë‚˜ìš”?\n",
    "\n",
    "ìœ„ ì •ë³´ë¥¼ ììœ ë¡­ê²Œ ë§ì”€í•´ì£¼ì‹œë©´, ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ìƒì„¸íˆ ê³„íší•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤! âœˆï¸\"\"\"\n",
    "\n",
    "# Gradio Blocksë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¤ìŠ¤í…€ ì¸í„°í˜ì´ìŠ¤ ìƒì„±\n",
    "with gr.Blocks(analytics_enabled=False) as demo:\n",
    "    gr.Markdown(\"# ğŸŒ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì • ê³„íš ì–´ì‹œìŠ¤í„´íŠ¸\")\n",
    "    gr.Markdown(\n",
    "        \"ì—¬í–‰ì§€, ê¸°ê°„, ì˜ˆì‚°, ì„ í˜¸ë„ë¥¼ ì•Œë ¤ì£¼ì‹œë©´ ë§ì¶¤í˜• ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ë“œë¦½ë‹ˆë‹¤!\"\n",
    "    )\n",
    "\n",
    "    # Temperature ìŠ¬ë¼ì´ë” ì¶”ê°€\n",
    "    temperature_slider = gr.Slider(\n",
    "        minimum=0.0,\n",
    "        maximum=1.0,\n",
    "        value=0.7,\n",
    "        step=0.1,\n",
    "        label=\"ğŸ¨ ì°½ì˜ì„± ì¡°ì ˆ (Temperature)\",\n",
    "        info=\"ë‚®ì„ìˆ˜ë¡(0.0) ì¼ê´€ë˜ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ë‹µë³€, ë†’ì„ìˆ˜ë¡(1.0) ì°½ì˜ì ì´ê³  ë‹¤ì–‘í•œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.\",\n",
    "        render=False,  # ChatInterface ë‚´ë¶€ì— í‘œì‹œ\n",
    "    )\n",
    "\n",
    "    # ì´ˆê¸° ë©”ì‹œì§€ê°€ ìˆëŠ” Chatbot ìƒì„± (ìµœì‹  Gradio í˜•ì‹)\n",
    "    chatbot = gr.Chatbot(\n",
    "        value=[{\"role\": \"assistant\", \"content\": initial_message}], height=500\n",
    "    )\n",
    "\n",
    "    # ChatInterface ìƒì„±\n",
    "    gr.ChatInterface(\n",
    "        fn=answer_invoke,\n",
    "        chatbot=chatbot,  # ì´ˆê¸° ë©”ì‹œì§€ê°€ ì„¤ì •ëœ chatbot ì‚¬ìš©\n",
    "        additional_inputs=[temperature_slider],\n",
    "        examples=[\n",
    "            [\"ì„œìš¸ì—ì„œ 2ë°• 3ì¼ ì—¬í–‰ ê³„íš ì§œì¤˜\", 0.7],\n",
    "            [\"ì œì£¼ë„ ê°€ì¡± ì—¬í–‰ ì¼ì • ì¶”ì²œí•´ì¤˜\", 0.3],\n",
    "            [\"ìœ ëŸ½ ë°°ë‚­ì—¬í–‰ 1ì£¼ì¼ ê³„íš ë„ì™€ì¤˜\", 0.1],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0334cda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7866\n"
     ]
    }
   ],
   "source": [
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì¢…ë£Œ\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e20357",
   "metadata": {},
   "source": [
    "[ì˜ˆì‹œ ë‹µì•ˆ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# ë©”ì‹œì§€ í”Œë ˆì´ìŠ¤í™€ë”ê°€ ìˆëŠ” í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ì—¬í–‰ ì¼ì •ì„ ê³„íší•´ì£¼ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"system\", \"ì‚¬ìš©ìì˜ ì„ í˜¸ë„ì— ë§ëŠ” ì—¬í–‰ ì¼ì •ì„ ìƒì„±í•©ë‹ˆë‹¤.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# LLM ëª¨ë¸ ì •ì˜\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\", \n",
    "    temperature=0.7, \n",
    "    top_p=0.9,\n",
    "    presence_penalty=0.3,\n",
    "    frequency_penalty=0.3,\n",
    "    )\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ + LLM ëª¨ë¸ + ì¶œë ¥íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì²˜ë¦¬í•˜ê³  AI ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ (chat_history ì‚¬ìš©)\n",
    "def answer_invoke(message, history):\n",
    "\n",
    "    history_messages = []\n",
    "    for msg in history:\n",
    "        if msg['role'] == \"user\":\n",
    "            history_messages.append(HumanMessage(content=msg['content']))\n",
    "        elif msg['role'] == \"assistant\":\n",
    "            history_messages.append(AIMessage(content=msg['content']))\n",
    "\n",
    "    history_messages.append(HumanMessage(content=message))\n",
    "    response = chain.invoke({\n",
    "        \"chat_history\": history_messages,\n",
    "        \"user_input\": message\n",
    "    })\n",
    "    return response\n",
    "\n",
    "# Gradio ChatInterface ê°ì²´ ìƒì„±\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,         # ë©”ì‹œì§€ ì²˜ë¦¬ í•¨ìˆ˜\n",
    "    title=\"ë§ì¶¤í˜• ì—¬í–‰ ì¼ì • ê³„íš ì–´ì‹œìŠ¤í„´íŠ¸\", # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ì˜ ì œëª©\n",
    "    )\n",
    "\n",
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio ì¸í„°í˜ì´ìŠ¤ ì¢…ë£Œ\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7895ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
