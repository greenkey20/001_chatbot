{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2631b5",
   "metadata": {},
   "source": [
    "#  Gradio 챗봇 구현 (간단한 QA 애플리케이션)\n",
    "\n",
    "### **학습 목표**\n",
    "1. Gradio ChatInterface의 다양한 기능을 이해한다\n",
    "2. LangChain LCEL을 활용한 챗봇 체인 구성 방법을 학습한다\n",
    "3. 채팅 히스토리를 관리하고 컨텍스트를 유지하는 방법을 익힌다\n",
    "4. 멀티모달 입력(텍스트+이미지)을 처리하는 챗봇을 구현한다\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfd9328",
   "metadata": {
    "id": "8bfd9328"
   },
   "source": [
    "##  환경 설정\n",
    "\n",
    "- 필수 라이브러리\n",
    "    - gradio\n",
    "    - langchain \n",
    "    - langchain-openai \n",
    "    - langchain-google-genai \n",
    "    - python-dotenv\n",
    "\n",
    "- `.env` 파일에 다음 API 키 설정\n",
    "\n",
    "    ```\n",
    "    OPENAI_API_KEY=your_openai_key\n",
    "    GOOGLE_API_KEY=your_google_key\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ac3ddb",
   "metadata": {
    "id": "15ac3ddb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129b8eee",
   "metadata": {
    "id": "129b8eee"
   },
   "source": [
    "## Simple QA Chain  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3722db67",
   "metadata": {
    "id": "3722db67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파이썬에서 리스트를 정렬하는 방법에는 여러 가지가 있습니다. 가장 일반적인 방법은 `sort()` 메서드와 `sorted()` 함수를 사용하는 것입니다.\n",
      "\n",
      "1. **`list.sort()` 메서드**  \n",
      "- 리스트 자체를 정렬하며, 정렬된 리스트를 반환하지 않고 원본 리스트를 변경합니다.  \n",
      "- 사용법:  \n",
      "```python\n",
      "my_list = [3, 1, 4, 2]\n",
      "my_list.sort()\n",
      "print(my_list)  # 출력: [1, 2, 3, 4]\n",
      "```\n",
      "\n",
      "2. **`sorted()` 함수**  \n",
      "- 원본 리스트는 변경하지 않고 정렬된 새 리스트를 반환합니다.  \n",
      "- 사용법:  \n",
      "```python\n",
      "my_list = [3, 1, 4, 2]\n",
      "sorted_list = sorted(my_list)\n",
      "print(sorted_list)  # 출력: [1, 2, 3, 4]\n",
      "```\n",
      "\n",
      "### 정렬 기준 지정하기\n",
      "- **`key` 인자**: 정렬 기준을 지정할 수 있습니다.  \n",
      "- **`reverse` 인자**: 내림차순 정렬을 원할 때 사용합니다 (`True`).\n",
      "\n",
      "예제: 문자열 길이 기준으로 정렬  \n",
      "```python\n",
      "words = ['apple', 'banana', 'cherry']\n",
      "words_sorted = sorted(words, key=len)\n",
      "print(words_sorted)  # 출력: ['apple', 'cherry', 'banana']\n",
      "```\n",
      "\n",
      "내림차순 정렬 예제:  \n",
      "```python\n",
      "numbers = [1, 3, 2, 4]\n",
      "numbers_sorted_desc = sorted(numbers, reverse=True)\n",
      "print(numbers_sorted_desc)  # 출력: [4, 3, 2, 1]\n",
      "```\n",
      "\n",
      "이 방법들을 활용해서 리스트를 원하는 방식으로 정렬하실 수 있습니다!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 파이썬(Python) 코드 작성을 도와주는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# LLM 모델 정의\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\", \n",
    "    temperature=0.3, \n",
    "    )\n",
    "\n",
    "# 프롬프트 템플릿 + LLM 모델 + 출력파서를 연결하여 체인 생성\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# 체인 실행\n",
    "response = chain.invoke({\n",
    "    \"user_input\": \"파이썬에서 리스트를 정렬하는 방법은 무엇인가요?\"\n",
    "})\n",
    "\n",
    "# AI의 응답 텍스트를 출력 \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e87eef4",
   "metadata": {
    "id": "9e87eef4"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "파이썬에서 리스트를 정렬하는 방법에는 여러 가지가 있습니다. 가장 일반적인 방법은 `sort()` 메서드와 `sorted()` 함수를 사용하는 것입니다.\n",
       "\n",
       "1. **`list.sort()` 메서드**  \n",
       "- 리스트 자체를 정렬하며, 정렬된 리스트를 반환하지 않고 원본 리스트를 변경합니다.  \n",
       "- 사용법:  \n",
       "```python\n",
       "my_list = [3, 1, 4, 2]\n",
       "my_list.sort()\n",
       "print(my_list)  # 출력: [1, 2, 3, 4]\n",
       "```\n",
       "\n",
       "2. **`sorted()` 함수**  \n",
       "- 원본 리스트는 변경하지 않고 정렬된 새 리스트를 반환합니다.  \n",
       "- 사용법:  \n",
       "```python\n",
       "my_list = [3, 1, 4, 2]\n",
       "sorted_list = sorted(my_list)\n",
       "print(sorted_list)  # 출력: [1, 2, 3, 4]\n",
       "```\n",
       "\n",
       "### 정렬 기준 지정하기\n",
       "- **`key` 인자**: 정렬 기준을 지정할 수 있습니다.  \n",
       "- **`reverse` 인자**: 내림차순 정렬을 원할 때 사용합니다 (`True`).\n",
       "\n",
       "예제: 문자열 길이 기준으로 정렬  \n",
       "```python\n",
       "words = ['apple', 'banana', 'cherry']\n",
       "words_sorted = sorted(words, key=len)\n",
       "print(words_sorted)  # 출력: ['apple', 'cherry', 'banana']\n",
       "```\n",
       "\n",
       "내림차순 정렬 예제:  \n",
       "```python\n",
       "numbers = [1, 3, 2, 4]\n",
       "numbers_sorted_desc = sorted(numbers, reverse=True)\n",
       "print(numbers_sorted_desc)  # 출력: [4, 3, 2, 1]\n",
       "```\n",
       "\n",
       "이 방법들을 활용해서 리스트를 원하는 방식으로 정렬하실 수 있습니다!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 마크다운 출력\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a59f9",
   "metadata": {},
   "source": [
    "## Gradio ChatInterface  \n",
    "- 설치: pip install gradio --upgrade , uv add gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17f810a",
   "metadata": {},
   "source": [
    "### 1) 기본 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65443d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n* Running on local URL:  http://127.0.0.1:7860\\n* To create a public link, set `share=True` in `launch()`.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 메시지: hello\n",
      "----------------------------------------\n",
      "채팅 히스토리:\n",
      "입력 메시지: who are you?\n",
      "----------------------------------------\n",
      "채팅 히스토리:\n",
      "사용자: user, 메시지: [{'text': 'hello', 'type': 'text'}]\n",
      "----------------------------------------\n",
      "사용자: assistant, 메시지: [{'text': '응답 메시지', 'type': 'text'}]\n",
      "----------------------------------------\n",
      "입력 메시지: ok\n",
      "----------------------------------------\n",
      "채팅 히스토리:\n",
      "사용자: user, 메시지: [{'text': 'hello', 'type': 'text'}]\n",
      "----------------------------------------\n",
      "사용자: assistant, 메시지: [{'text': '응답 메시지', 'type': 'text'}]\n",
      "----------------------------------------\n",
      "사용자: user, 메시지: [{'text': 'who are you?', 'type': 'text'}]\n",
      "----------------------------------------\n",
      "사용자: assistant, 메시지: [{'text': '응답 메시지', 'type': 'text'}]\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# 챗봇 함수 정의\n",
    "def chat_function(message, history):\n",
    "    # 메시지 출력\n",
    "    print(f\"입력 메시지: {message}\")\n",
    "    print(\"-\"*40)\n",
    "    # 채팅 히스토리 출력\n",
    "    print(f\"채팅 히스토리:\")\n",
    "    for chat in history:\n",
    "        print(f\"사용자: {chat['role']}, 메시지: {chat['content']}\")\n",
    "        print(\"-\"*40)\n",
    "    return \"응답 메시지\"\n",
    "\n",
    "# 챗봇 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_function,  # 실행할 함수\n",
    "    analytics_enabled=False,  # 사용 정보 제공 여부\n",
    ")\n",
    "\n",
    "# 챗봇 인터페이스 실행\n",
    "demo.launch()\n",
    "\n",
    "\"\"\"\n",
    "* Running on local URL:  http://127.0.0.1:7860\n",
    "* To create a public link, set `share=True` in `launch()`.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6df357c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7860\n"
     ]
    }
   ],
   "source": [
    "# 인터페이스 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070bc3e",
   "metadata": {},
   "source": [
    "### 2) 간단한 예제: Echo 챗봇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df39e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def echo_bot(message, history):\n",
    "    return f\"당신이 입력한 메시지: {message}\"\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=echo_bot,\n",
    "    title=\"Echo 챗봇\",\n",
    "    description=\"입력한 메시지를 그대로 되돌려주는 챗봇입니다.\",\n",
    "    analytics_enabled=False,  \n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eea11f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c3c244",
   "metadata": {},
   "source": [
    "### 3) 스트리밍 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d36896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스트리밍 챗봇 함수 정의\n",
    "import time\n",
    "\n",
    "def streaming_bot(message, history):\n",
    "    response = f\"처리 중인 메시지: {message}\"\n",
    "    for i in range(len(response)):\n",
    "        time.sleep(0.1)          # 0.1초 대기\n",
    "        yield response[:i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f38cc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스트리밍 챗봇 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=streaming_bot,\n",
    "    title=\"스트리밍 챗봇\",\n",
    "    description=\"입력한 메시지를 한 글자씩 처리하는 챗봇입니다.\",\n",
    "    analytics_enabled=False,  \n",
    ")\n",
    "\n",
    "# 스트리밍 챗봇 인터페이스 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ffdd862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5129fcd",
   "metadata": {},
   "source": [
    "### 4) 추가 입력 컴포넌트\n",
    "- 최대 응답 길이 등 기타 설정을 위한 추가 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d6069ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 파이썬(Python) 코드 작성을 도와주는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "\n",
    "# 챗봇 함수 정의\n",
    "def chat_function(message, history, model, temperature):\n",
    "\n",
    "    if model == \"gpt-4.1-nano\":\n",
    "        model = ChatOpenAI(model=model, temperature=temperature)\n",
    "    elif model == \"gemini-2.5-flash-lite\":\n",
    "        model = ChatGoogleGenerativeAI(model=model, temperature=temperature)\n",
    "\n",
    "    chain = prompt | model | StrOutputParser()\n",
    "\n",
    "    response = chain.invoke({\n",
    "        \"user_input\": message\n",
    "    })\n",
    "    return response\n",
    "\n",
    "# 챗봇 인터페이스 생성\n",
    "with gr.Blocks() as demo:\n",
    "    model_selector = gr.Dropdown([\"gpt-4.1-nano\", \"gemini-2.5-flash-lite\"], label=\"모델 선택\")\n",
    "    slider = gr.Slider(0.0, 1.0, label=\"Temperature\", value=0.3, step=0.1, render=False)   \n",
    "\n",
    "    gr.ChatInterface(\n",
    "        fn=chat_function, \n",
    "        additional_inputs=[model_selector, slider],\n",
    "        analytics_enabled=False,  \n",
    "    )\n",
    "\n",
    "# 챗봇 인터페이스 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff42f636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c70ea",
   "metadata": {},
   "source": [
    "### 5) 예시 질문 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c44c455e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 스트리밍 챗봇 인터페이스 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=streaming_bot,\n",
    "    title=\"스트리밍 챗봇\",\n",
    "    description=\"입력한 메시지를 한 글자씩 처리하는 챗봇입니다.\",\n",
    "    analytics_enabled=False,  \n",
    "    examples=[\n",
    "        \"파이썬 코드를 작성하는 방법을 알려주세요\",\n",
    "        \"파이썬에서 리스트를 정렬하는 방법은 무엇인가요?\",\n",
    "    ]    \n",
    ")\n",
    "\n",
    "# 스트리밍 챗봇 인터페이스 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b16cb24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7862\n"
     ]
    }
   ],
   "source": [
    "demo.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0309e370",
   "metadata": {},
   "source": [
    "### 6) 멀티모달 기능\n",
    "- `multimodal=True` 옵션\n",
    "- 이미지나 파일을 처리할 수 있는 멀티모달 챗봇 구현\n",
    "\n",
    "- message 파라미터:\n",
    "    ```python\n",
    "    {\n",
    "        \"text\": \"user input\", \n",
    "        \"files\": [\n",
    "            \"updated_file_1_path.ext\",\n",
    "            \"updated_file_2_path.ext\", \n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "    ```\n",
    "- history 파라미터:\n",
    "    ```python\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": (\"cat1.png\")},\n",
    "        {\"role\": \"user\", \"content\": (\"cat2.png\")},\n",
    "        {\"role\": \"user\", \"content\": \"What's the difference between these two images?\"},\n",
    "    ]\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709da9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History: []\n",
      "Filepath list: ['/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/64acc6368053ea48efe74d877ce608aee21abedc26ea8842fddb22545d2b34f5/20230816 15h photoism_key square.jpeg', '/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/8fc633a591dd278321a4ade8be3015f1d508529f23f2ea8a8a8981d949f4072d/avatar-profile.png']\n",
      "History: [{'role': 'user', 'metadata': None, 'content': [{'file': {'path': '/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/64acc6368053ea48efe74d877ce608aee21abedc26ea8842fddb22545d2b34f5/20230816 15h photoism_key square.jpeg', 'url': '/gradio_api/file=/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/64acc6368053ea48efe74d877ce608aee21abedc26ea8842fddb22545d2b34f5/20230816 15h photoism_key square.jpeg', 'size': None, 'orig_name': None, 'mime_type': 'image/jpeg', 'is_stream': False, 'meta': {'_type': 'gradio.FileData'}}, 'alt_text': None, 'type': 'file'}, {'file': {'path': '/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/8fc633a591dd278321a4ade8be3015f1d508529f23f2ea8a8a8981d949f4072d/avatar-profile.png', 'url': '/gradio_api/file=/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/8fc633a591dd278321a4ade8be3015f1d508529f23f2ea8a8a8981d949f4072d/avatar-profile.png', 'size': None, 'orig_name': None, 'mime_type': 'image/png', 'is_stream': False, 'meta': {'_type': 'gradio.FileData'}}, 'alt_text': None, 'type': 'file'}, {'text': '첨부한 두 이미지의 차이가 뭐야?', 'type': 'text'}], 'options': None}, {'role': 'assistant', 'metadata': None, 'content': [{'text': '두 이미지는 다음과 같은 점에서 차이가 있습니다.\\n\\n* **스타일:** 첫 번째 이미지는 실제 사람의 사진이고, 두 번째 이미지는 픽셀 아트 스타일의 캐릭터입니다.\\n* **표현:** 첫 번째 이미지의 여성은 미소를 짓고 있으며, 두 번째 이미지의 캐릭터도 웃는 표정을 하고 있지만 픽셀화되어 표현이 단순합니다.\\n* **형태:** 첫 번째 이미지의 여성은 실제 사람의 윤곽을 가지고 있지만, 두 번째 이미지의 캐릭터는 동글동글하고 귀여운 형태로 디자인되었습니다.\\n* **색상:** 첫 번째 이미지는 실제 색상을 반영하지만, 두 번째 이미지는 픽셀 아트 특성상 제한된 색상 팔레트를 사용하며, 배경색도 다릅니다.\\n* **디테일:** 첫 번째 이미지에는 머리카락, 옷의 주름 등 더 많은 디테일이 있지만, 두 번째 이미지는 픽셀화되어 디테일이 최소화되어 있습니다.', 'type': 'text'}], 'options': None}]\n",
      "Filepath list: ['/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/64acc6368053ea48efe74d877ce608aee21abedc26ea8842fddb22545d2b34f5/20230816 15h photoism_key square.jpeg', '/private/var/folders/y2/5m8dl9kj7yl_xvfwnl0xlj8m0000gn/T/gradio/8fc633a591dd278321a4ade8be3015f1d508529f23f2ea8a8a8981d949f4072d/avatar-profile.png']\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "def convert_to_url(image_path):\n",
    "    \"\"\"이미지를 URL 형식으로 변환\"\"\"\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        # 이미지를 base64로 인코딩\n",
    "        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        return f\"data:image/jpeg;base64,{encoded_string}\"\n",
    "\n",
    "def multimodal_bot(message, history):\n",
    "\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")\n",
    "    \n",
    "    if isinstance(message, dict):\n",
    "        # 텍스트와 파일 추출\n",
    "        text = message.get(\"text\", \"\")\n",
    "        \n",
    "        # 히스토리와 현재 메시지에서 모든 파일 경로 추출\n",
    "        filepath_list = []\n",
    "        \n",
    "        # 히스토리에서 이미지 파일 추출\n",
    "        print(\"History:\", history)  # 디버깅용\n",
    "        for exchange in history:\n",
    "            # user_message = exchange[0]\n",
    "            # if isinstance(user_message, tuple):  # 이미지 메시지 확인\n",
    "            #     filepath_list.append(user_message[0])\n",
    "            # 새로운 Gradio 형식: exchange는 딕셔너리\n",
    "            if isinstance(exchange, dict) and 'content' in exchange:\n",
    "                content = exchange['content']\n",
    "                # content는 리스트 형태\n",
    "                if isinstance(content, list):\n",
    "                    for item in content:\n",
    "                        # 파일 타입 아이템 찾기\n",
    "                        if isinstance(item, dict) and item.get('type') == 'file':\n",
    "                            file_info = item.get('file', {})\n",
    "                            if 'path' in file_info:\n",
    "                                filepath_list.append(file_info['path'])\n",
    "        \n",
    "        # 현재 메시지의 파일들도 추가\n",
    "        files = message.get(\"files\", [])\n",
    "        filepath_list.extend(files)\n",
    "        \n",
    "        print(\"Filepath list:\", filepath_list)  # 디버깅용\n",
    "        \n",
    "        if filepath_list:\n",
    "            # 모든 이미지 처리\n",
    "            image_urls = []\n",
    "            for file_path in filepath_list:\n",
    "                try:\n",
    "                    image_url = convert_to_url(file_path)\n",
    "                    image_urls.append({\"type\": \"image_url\", \"image_url\": image_url})\n",
    "                except Exception as e:\n",
    "                    print(f\"이미지 처리 중 오류 발생: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if not image_urls:\n",
    "                return \"이미지 처리 중 오류가 발생했습니다.\"\n",
    "            \n",
    "            # 메시지 구성\n",
    "            content = [\n",
    "                {\"type\": \"text\", \"text\": text if text else \"이 이미지들에 대해 설명해주세요.\"},\n",
    "                *image_urls\n",
    "            ]\n",
    "            \n",
    "            try:\n",
    "                # API 호출\n",
    "                response = model.invoke([\n",
    "                    HumanMessage(content=content)\n",
    "                ])\n",
    "                return response.content\n",
    "            except Exception as e:\n",
    "                return f\"모델 응답 생성 중 오류가 발생했습니다: {str(e)}\"\n",
    "        \n",
    "        return text if text else \"이미지를 업로드해주세요.\"\n",
    "    \n",
    "    return \"텍스트나 이미지를 입력해주세요.\"\n",
    "\n",
    "# Gradio 인터페이스 설정\n",
    "demo = gr.ChatInterface(\n",
    "    fn=multimodal_bot,\n",
    "    multimodal=True,\n",
    "    title=\"멀티모달 챗봇\",\n",
    "    description=\"텍스트와 이미지를 함께 처리할 수 있는 챗봇입니다. 이전 대화의 이미지들도 함께 고려합니다.\",\n",
    "    analytics_enabled=False,  \n",
    "    textbox=gr.MultimodalTextbox(placeholder=\"텍스트를 입력하거나 이미지를 업로드해주세요.\", file_count=\"multiple\", file_types=[\"image\"]),\n",
    ")\n",
    "\n",
    "# 인터페이스 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8086535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7863\n"
     ]
    }
   ],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae3e9b8",
   "metadata": {},
   "source": [
    "### 7) PDF 뷰어\n",
    "- 설치: pip install gradio_pdf 또는 uv add gradio_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f63e62dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gradio_pdf import PDF\n",
    "\n",
    "def answer_invoke(message, history):\n",
    "    # TODO: PDF 처리 로직 추가 필요\n",
    "    # 현재는 사용자 메시지만 반환하는 예시입니다\n",
    "    # 실제 구현 시 PDF 파싱 라이브러리(PyPDF2, pdfplumber 등) 필요\n",
    "    return message\n",
    "\n",
    "with gr.Blocks(\n",
    "    analytics_enabled=False,  \n",
    ") as demo:\n",
    "    with gr.Row():\n",
    "        # API Key Section\n",
    "        api_key_input = gr.Textbox(\n",
    "            label=\"Enter OpenAI API Key\",\n",
    "            type=\"password\",\n",
    "            placeholder=\"sk-...\"\n",
    "        )\n",
    "        \n",
    "    with gr.Row():\n",
    "        # PDF Upload and Chat Interface\n",
    "        with gr.Column(scale=2):\n",
    "            pdf_file = PDF(\n",
    "                label=\"Upload PDF File\",\n",
    "                height=600,  # PDF 뷰어 높이 설정\n",
    "            )\n",
    "        with gr.Column(scale=1):\n",
    "            chatbot = gr.ChatInterface(\n",
    "                fn=answer_invoke,\n",
    "                title=\"PDF-based Chatbot\",\n",
    "                description=\"Upload a PDF file and ask questions about its contents.\",\n",
    "            )\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db19ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7369f37",
   "metadata": {},
   "source": [
    "## Memory 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3d508b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chat_history 플레이스홀더를 사용\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# 메시지 플레이스홀더가 있는 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 파이썬(Python) 코드 작성을 도와주는 AI 어시스턴트입니다.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"system\", \"이전 대화 내용을 참고하여 질문에 대해서 친절하게 답변합니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# 프롬프트 템플릿 + LLM 모델 + 출력파서를 연결하여 체인 생성\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "\n",
    "# 사용자 메시지를 처리하고 AI 응답을 생성하는 함수 (chat_history 사용)\n",
    "def answer_invoke(message, history):\n",
    "\n",
    "    history_messages = []\n",
    "    for msg in history:\n",
    "        if msg['role'] == \"user\":\n",
    "            history_messages.append(HumanMessage(content=msg['content']))\n",
    "        elif msg['role'] == \"assistant\":\n",
    "            history_messages.append(AIMessage(content=msg['content']))\n",
    "\n",
    "    # history_messages.append(HumanMessage(content=message)) # 나의 질문 = 이 line 필요 없다고 하신 이유 이해 못함/앞뒤 설명 못 들음\n",
    "    response = chain.invoke({\n",
    "        \"chat_history\": history_messages,\n",
    "        \"user_input\": message\n",
    "    })\n",
    "    return response\n",
    "    \n",
    "\n",
    "# Gradio ChatInterface 객체 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,         # 메시지 처리 함수\n",
    "    title=\"파이썬 코드 어시스턴트\", # 채팅 인터페이스의 제목\n",
    "    )\n",
    "\n",
    "# Gradio 인터페이스 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "576dbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio 인터페이스 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367d46b8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# [실습 프로젝트]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5b260a",
   "metadata": {},
   "source": [
    "### **다음과 같은 요구사항을 Gradio ChatInterface로 구현합니다**\n",
    "\n",
    "- 주제: 맞춤형 여행 일정 계획 어시스턴트\n",
    "- 기능: \n",
    "   - OpenAI Chat Completion API와 LangChain을 활용하여 사용자의 선호도에 맞는 여행 일정을 생성\n",
    "   - LCEL을 사용하여 단계별 프롬프트 체인 구성 (사용자 입력 분석 -> 일정 생성 -> 세부 계획 수립)\n",
    "   - 채팅 히스토리 사용하여 답변 생성\n",
    "   - Gradio 인터페이스를 통해 사용자와 대화형으로 상호작용\n",
    "\n",
    "- 주요 포인트:\n",
    "\n",
    "   1. **모델 매개변수 최적화**\n",
    "      - temperature=0.7: 적당한 창의성을 유지하면서 일관된 응답 생성\n",
    "      - top_p=0.9: 높은 확률의 토큰만 선택하여 응답의 품질 향상\n",
    "      - presence_penalty와 frequency_penalty: 반복적인 응답을 줄이고 다양한 제안 생성\n",
    "\n",
    "   2. **시스템 프롬프트 설계**\n",
    "      - 여행 플래너로서의 역할과 응답 가이드라인을 명확히 정의\n",
    "      - 구체적인 정보를 포함하도록 지시\n",
    "      - 한국어 응답 명시\n",
    "\n",
    "   3. **메모리 관리**\n",
    "      - Gradio 또는 LangChain 메모리 기능을 사용하여 대화 컨텍스트 유지\n",
    "      - 이전 대화 내용을 바탕으로 연속성 있는 응답 생성\n",
    "\n",
    "### 단계별 구현 가이드\n",
    "\n",
    "- **Step 1**: 시스템 프롬프트 작성\n",
    "   - 여행 플래너의 역할 명시\n",
    "   - 구체적인 정보 포함 지시 (날짜, 장소, 예산 등)\n",
    "\n",
    "- **Step 2**: 채팅 히스토리 관리\n",
    "   - MessagesPlaceholder 사용\n",
    "   - HumanMessage/AIMessage 변환\n",
    "\n",
    "- **Step 3**: Gradio 인터페이스 설정\n",
    "   - 제목과 설명 추가\n",
    "\n",
    "**Step 4**: 테스트\n",
    "   - \"서울에서 2박 3일 여행 계획 짜줘\" 등의 질문 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5763e1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기에 코드를 작성하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e20357",
   "metadata": {},
   "source": [
    "[예시 답안]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c6a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 임포트\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "\n",
    "# 메시지 플레이스홀더가 있는 프롬프트 템플릿 정의\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"여행 일정을 계획해주는 AI 어시스턴트입니다.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"system\", \"사용자의 선호도에 맞는 여행 일정을 생성합니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# LLM 모델 정의\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4.1-nano\", \n",
    "    temperature=0.7, \n",
    "    top_p=0.9,\n",
    "    presence_penalty=0.3,\n",
    "    frequency_penalty=0.3,\n",
    "    )\n",
    "\n",
    "# 프롬프트 템플릿 + LLM 모델 + 출력파서를 연결하여 체인 생성\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "# 사용자 메시지를 처리하고 AI 응답을 생성하는 함수 (chat_history 사용)\n",
    "def answer_invoke(message, history):\n",
    "\n",
    "    history_messages = []\n",
    "    for msg in history:\n",
    "        if msg['role'] == \"user\":\n",
    "            history_messages.append(HumanMessage(content=msg['content']))\n",
    "        elif msg['role'] == \"assistant\":\n",
    "            history_messages.append(AIMessage(content=msg['content']))\n",
    "\n",
    "    history_messages.append(HumanMessage(content=message))\n",
    "    response = chain.invoke({\n",
    "        \"chat_history\": history_messages,\n",
    "        \"user_input\": message\n",
    "    })\n",
    "    return response\n",
    "\n",
    "# Gradio ChatInterface 객체 생성\n",
    "demo = gr.ChatInterface(\n",
    "    fn=answer_invoke,         # 메시지 처리 함수\n",
    "    title=\"맞춤형 여행 일정 계획 어시스턴트\", # 채팅 인터페이스의 제목\n",
    "    )\n",
    "\n",
    "# Gradio 인터페이스 실행\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469bcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradio 인터페이스 종료\n",
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7895ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
